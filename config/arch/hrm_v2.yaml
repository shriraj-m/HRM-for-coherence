# HRM v2 architecture for NLP tasks (HotpotQA, SCAN, CFQ)
name: models.hrm.hrm_act_v2@HierarchicalReasoningModel_ACTV2
loss:
  name: losses@ACTLossHead
  loss_type: stablemax_cross_entropy

# ACT halting parameters
halt_exploration_prob: 0.1
halt_max_steps: 16

# Hierarchical cycles
H_cycles: 2
L_cycles: 2

# Layer depths
H_layers: 4
L_layers: 4

# Model dimensions
hidden_size: 512
num_heads: 8  # min(2, hidden_size // 64)
expansion: 4

# NLP-specific parameters
max_sentences: 20
use_cross_attention: true
sentence_pooling: mean

# Puzzle embeddings (not used for NLP)
puzzle_emb_ndim: 0
num_puzzle_identifiers: 1

# Positional encodings
pos_encodings: rope